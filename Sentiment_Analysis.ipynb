{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio-Exam Part I - Sentiment Analysis\n",
    "\n",
    "* Social Media Analytics - MADS-SMA\n",
    "* Valentin Werger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different approaches\n",
    "# Train own word embedding\n",
    "# Use model trained on yelp for other data\n",
    "# Try out sentiments towards types of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required ML packages and functions\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV, RandomizedSearchCV, RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy.stats import uniform, randint\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Hamburg Yelp reviews\n",
    "yelp = pd.read_csv(\"data/yelp_reviews_hamburg_en.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3025 entries, 0 to 3024\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   url     3025 non-null   object        \n",
      " 1   stars   3025 non-null   float64       \n",
      " 2   text    3025 non-null   object        \n",
      " 3   date    3025 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 94.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Overview of the data\n",
    "yelp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.yelp.com/biz/il-buco-hamburg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fantastic little restaurant!Great staff and fo...</td>\n",
       "      <td>2017-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.yelp.com/biz/campus-suite-hamburg-7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>We went there to grab some breakfast. They are...</td>\n",
       "      <td>2015-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.yelp.com/biz/campus-suite-hamburg-7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good coffee,  sandwiches,  and yogurts close t...</td>\n",
       "      <td>2016-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.yelp.com/biz/campus-suite-hamburg-7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>When XING handed out coupons for free coffee d...</td>\n",
       "      <td>2008-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.yelp.com/biz/campus-suite-hamburg-7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I love Campus Suite franchise. after the Balza...</td>\n",
       "      <td>2010-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               url  stars  \\\n",
       "0         https://www.yelp.com/biz/il-buco-hamburg    5.0   \n",
       "1  https://www.yelp.com/biz/campus-suite-hamburg-7    4.0   \n",
       "2  https://www.yelp.com/biz/campus-suite-hamburg-7    4.0   \n",
       "3  https://www.yelp.com/biz/campus-suite-hamburg-7    3.0   \n",
       "4  https://www.yelp.com/biz/campus-suite-hamburg-7    4.0   \n",
       "\n",
       "                                                text       date  \n",
       "0  Fantastic little restaurant!Great staff and fo... 2017-08-12  \n",
       "1  We went there to grab some breakfast. They are... 2015-09-29  \n",
       "2  Good coffee,  sandwiches,  and yogurts close t... 2016-01-13  \n",
       "3  When XING handed out coupons for free coffee d... 2008-04-24  \n",
       "4  I love Campus Suite franchise. after the Balza... 2010-01-15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 5 rows\n",
    "yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract name of the location from url\n",
    "yelp[\"name\"] = yelp.apply(lambda row: re.sub(\"https://www.yelp.com/biz/\", \"\", row[\"url\"]), axis=1)\n",
    "yelp = yelp.drop(columns=\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect length of review text\n",
    "text_length_distribution = np.array([len(text) for text in yelp.text])\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=[15,8])\n",
    "sns.histplot(data = text_length_distribution)\n",
    "\n",
    "# Problem: Maximum length of Bert is 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    1359\n",
       "4.0     974\n",
       "3.0     395\n",
       "2.0     157\n",
       "1.0     140\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='stars', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check distribution of ratings\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=[15,8])\n",
    "sns.countplot(data = yelp, x = \"stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading glove-wiki-gigaword-50\n",
      "Downloading glove-twitter-50\n",
      "Downloading word2vec-google-news-300\n"
     ]
    }
   ],
   "source": [
    "# Load potential sets of word vectors\n",
    "#list(gensim.downloader.info()['models'].keys())\n",
    "potential_wv = {}\n",
    "print(\"Downloading glove-wiki-gigaword-50\")\n",
    "potential_wv[\"wv_glove_wiki\"] = gensim.downloader.load('glove-wiki-gigaword-300')\n",
    "print(\"Downloading glove-twitter-50\")\n",
    "potential_wv[\"wv_glove_twitter\"] = gensim.downloader.load('glove-twitter-200')\n",
    "print(\"Downloading word2vec-google-news-300\")\n",
    "potential_wv[\"wv_word2vec\"] = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analyser class\n",
    "class SentimentAnalyser():\n",
    "\n",
    "    def __init__(self, data, target, normalize = True):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.target_distribution = self.data[self.target].value_counts(normalize=True)\n",
    "\n",
    "        # Normalize the review texts\n",
    "        if normalize:\n",
    "            self.data[\"text\"] = self.normalize()\n",
    "\n",
    "        # Initialize container for experiment results\n",
    "        self.experiment_results = {}\n",
    "        self.__run = 1\n",
    "\n",
    "        # Produce word embeddings for the whole dataset\n",
    "        self.word_embeddings = {}\n",
    "        for vector_set in [\"wv_glove_wiki\", \"wv_glove_twitter\", \"wv_word2vec\"]:\n",
    "            self.word_embeddings[vector_set] = self.produce_embeddings(self.data.text, vector_set)\n",
    "\n",
    "        # Set up experiments to conduct\n",
    "        self.experiments = [\n",
    "            {\n",
    "                'name': 'Logistic Regression',\n",
    "                'model': LogisticRegression(n_jobs = os.cpu_count() -1, solver=\"saga\", l1_ratio=0.5),\n",
    "                'params': {\n",
    "                    'preprocessor': [\n",
    "                        self.__WordCountTransformerHelper(min_df=1, ngram_range=(1,1), data=self.data),\n",
    "                        self.__WordCountTransformerHelper(min_df=2, ngram_range=(1,1), data=self.data),\n",
    "                        self.__WordCountTransformerHelper(min_df=3, ngram_range=(1,1), data=self.data),\n",
    "                        self.__WordCountTransformerHelper(min_df=1, ngram_range=(1,2), data=self.data),\n",
    "                        self.__TfidfTransformerHelper(norm=\"l2\", data=self.data),\n",
    "                        self.__TfidfTransformerHelper(norm=\"l1\", data=self.data),\n",
    "                        self.__WordEmbeddingHelper(data=self.word_embeddings[\"wv_glove_wiki\"]),\n",
    "                        self.__WordEmbeddingHelper(data=self.word_embeddings[\"wv_glove_twitter\"]),\n",
    "                        self.__WordEmbeddingHelper(data=self.word_embeddings[\"wv_word2vec\"]),\n",
    "                        #FunctionTransformer(self.word_embedding_helper_function, kw_args={'wv':\"wv_glove_wiki\"}),\n",
    "                        #FunctionTransformer(self.word_embedding_helper_function, kw_args={'wv':\"wv_glove_twitter\"}),\n",
    "                        #FunctionTransformer(self.word_embedding_helper_function, kw_args={'wv':\"wv_word2vec\"})\n",
    "                        ],\n",
    "                    'oversampler': ['passthrough', SMOTE(random_state=33)],\n",
    "                    'estimator__penalty': [\"none\", \"l2\", \"l1\", \"elasticnet\"],\n",
    "                    'estimator__C': [0.5, 1, 2]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'KNeighbors',\n",
    "                'model': KNeighborsClassifier(algorithm = \"auto\", n_jobs = os.cpu_count() -1),\n",
    "                'params': {\n",
    "                    'preprocessor': [\n",
    "                        CountVectorizer(min_df=1), \n",
    "                        CountVectorizer(min_df=2), \n",
    "                        CountVectorizer(min_df=3), \n",
    "                        CountVectorizer(ngram_range=(1,2)),\n",
    "                        TfidfVectorizer(norm='l1'),\n",
    "                        TfidfVectorizer(norm='l2'),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_wiki\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_twitter\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_word2vec\"})\n",
    "                        ],\n",
    "                    'oversampler': ['passthrough', SMOTE(random_state=33)],\n",
    "                    'estimator__n_neighbors': randint(1, 10), \n",
    "                    'estimator__weights': [\"uniform\", \"distance\"], \n",
    "                    'estimator__metric': [\"euclidean\", \"manhattan\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'Random Forest',\n",
    "                'model': RandomForestClassifier(n_jobs = os.cpu_count() -1, verbose = 1, random_state = 33),\n",
    "                'params': {\n",
    "                    'preprocessor': [\n",
    "                        CountVectorizer(min_df=1), \n",
    "                        CountVectorizer(min_df=2), \n",
    "                        CountVectorizer(min_df=3), \n",
    "                        CountVectorizer(ngram_range=(1,2)),\n",
    "                        TfidfVectorizer(norm='l1'),\n",
    "                        TfidfVectorizer(norm='l2'),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_wiki\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_twitter\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_word2vec\"})\n",
    "                        ],\n",
    "                    'oversampler': ['passthrough', SMOTE(random_state=33)],\n",
    "                    'estimator__criterion': ['gini', 'entropy'],\n",
    "                    'estimator__n_estimators': randint(1, 100), \n",
    "                    'estimator__max_features': uniform(0.1,0.9),\n",
    "                    'estimator__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "                    'estimator__ccp_alpha': uniform(0,0.1)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'SVM',\n",
    "                'model': SVC(verbose = True, random_state = 33),\n",
    "                'params': {\n",
    "                    'preprocessor': [\n",
    "                        CountVectorizer(min_df=1), \n",
    "                        CountVectorizer(min_df=2), \n",
    "                        CountVectorizer(min_df=3), \n",
    "                        CountVectorizer(ngram_range=(1,2)),\n",
    "                        TfidfVectorizer(norm='l1'),\n",
    "                        TfidfVectorizer(norm='l2'),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_wiki\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_twitter\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_word2vec\"})\n",
    "                        ],\n",
    "                    'oversampler': ['passthrough', SMOTE(random_state=33)],\n",
    "                    'estimator__C': uniform(0.001, 1),\n",
    "                    'estimator__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                    'estimator__degree': randint(1, 5),\n",
    "                    'estimator__gamma': uniform(0.0001, 1),\n",
    "                    'estimator__class_weight': [None, 'balanced']\n",
    "                }\n",
    "            },\n",
    "            # When in doubt use XGBoost\n",
    "            {\n",
    "                'name': 'XGBoost',\n",
    "                'model': XGBClassifier(\n",
    "                    objective = \"multi:softprob\",\n",
    "                    num_class = 5, \n",
    "                    tree_method = \"auto\",\n",
    "                    eval_metric = \"auc\", \n",
    "                    verbosity = 1,\n",
    "                    use_label_encoder = False,\n",
    "                    random_state = 33),\n",
    "                'params': {\n",
    "                    'preprocessor': [\n",
    "                        CountVectorizer(min_df=1), \n",
    "                        CountVectorizer(min_df=2), \n",
    "                        CountVectorizer(min_df=3), \n",
    "                        CountVectorizer(ngram_range=(1,2)),\n",
    "                        TfidfVectorizer(norm='l1'),\n",
    "                        TfidfVectorizer(norm='l2'),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_wiki\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_glove_twitter\"}),\n",
    "                        FunctionTransformer(self.produce_embeddings, kw_args={'wv':\"wv_word2vec\"})\n",
    "                        ],\n",
    "                    'oversampler': ['passthrough', SMOTE(random_state=33)],\n",
    "                    'estimator__learning_rate': uniform(0.001, 0.5),\n",
    "                    'estimator__gamma': uniform(0, 0.5),\n",
    "                    'estimator__max_depth': randint(3, 10),\n",
    "                    'estimator__colsample_bytree': uniform(0.5, 0.5)\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def __normalize_document(self, doc, tokenizer, stop_words):\n",
    "        doc = re.sub(r'@[\\w]+', '', doc)          # replace user mentions\n",
    "        doc = re.sub(r'http[\\S]+', 'URL', doc)    # replace URLs\n",
    "        doc = re.sub(r'[^\\w\\s]', '', doc)         # keep words and spaces\n",
    "        doc = doc.lower()\n",
    "        doc = doc.strip()\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        doc = ' '.join(filtered_tokens)\n",
    "        return doc\n",
    "\n",
    "    def normalize(self):\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "        return self.data.text.apply(lambda x: self.__normalize_document(x, wpt, stop_words))\n",
    "\n",
    "    def naive_baseline(self):\n",
    "        self.data[\"naive_baseline_prediction\"] = np.random.choice(self.target_distribution.index.to_numpy(), size = len(self.data), replace = True, p = self.target_distribution.values)\n",
    "\n",
    "    def vader_sentiment(self):\n",
    "        vader = SentimentIntensityAnalyzer()\n",
    "        self.data['vader_scores'] = self.data.text.apply(lambda x: vader.polarity_scores(x))\n",
    "        self.data['vader_compound'] = self.data.vader_scores.apply(lambda x: x['compound'])\n",
    "        self.data['vader_prediction'] = self.data.vader_compound.apply(lambda x: 1 if x >= 0 else 0)\n",
    "        pd.crosstab(self.data[self.target], self.data.vader_prediction, normalize='all')\n",
    "\n",
    "    def textblob_sentiment(self):\n",
    "        self.data['textblob_score'] = self.data.text.apply(\n",
    "            lambda review: TextBlob(review).sentiment[0])\n",
    "        self.data['textblob_prediction'] = self.data.textblob_score.apply(lambda x: 1 if x >= 0 else 0)\n",
    "        pd.crosstab(self.data[self.target], self.data.textblob_prediction, normalize='all')\n",
    "\n",
    "    def produce_embeddings(self, X, wv):\n",
    "        print(f\"Produce word embeddings for - {wv}\")\n",
    "\n",
    "        vocabulary = set(potential_wv[wv].index_to_key)\n",
    "        wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "        def avg_embeddings(document):\n",
    "            words = wpt.tokenize(document)\n",
    "            invocab = [word for word in words if word in vocabulary]\n",
    "            avg = np.mean(potential_wv[wv][invocab], axis=0) if len(invocab) >= 1 else []\n",
    "            return avg\n",
    "\n",
    "        doc_embeddings = np.array([avg_embeddings(doc) for doc in X.values])\n",
    "        return doc_embeddings\n",
    "\n",
    "    def word_embedding_helper_function(self, X, wv):\n",
    "        embedding = self.word_embeddings[wv]\n",
    "        return embedding[X]\n",
    "\n",
    "    class __WordEmbeddingHelper(TransformerMixin, BaseEstimator):\n",
    "\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return self.data[X]\n",
    "\n",
    "    class __WordCountTransformerHelper(TransformerMixin, BaseEstimator):\n",
    "\n",
    "        def __init__(self, data, min_df=1, ngram_range=(1,1)):\n",
    "            self.data = data\n",
    "            self.min_df = min_df\n",
    "            self.ngram_range = ngram_range\n",
    "            self.transformer = CountVectorizer(min_df=self.min_df, ngram_range=self.ngram_range)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.transformer.fit(self.data.text[X])\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return self.transformer.transform(self.data.text[X])\n",
    "\n",
    "    class __TfidfTransformerHelper(TransformerMixin, BaseEstimator):\n",
    "\n",
    "        def __init__(self, data, norm=\"l2\"):\n",
    "            self.data = data\n",
    "            self.norm = norm\n",
    "            self.transformer = TfidfVectorizer(norm=self.norm)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.transformer.fit(self.data.text[X])\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return self.transformer.transform(self.data.text[X])\n",
    "\n",
    "\n",
    "    def evaluate_classifier(self, name, model, params, iterations, cv_splits, cv_repeats):\n",
    "\n",
    "        class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "            def transform(self, X):\n",
    "                # Comment in the following line to print data shape during Pipeline\n",
    "                #print(X.shape)\n",
    "                return X\n",
    "\n",
    "            def fit(self, X, y=None, **fit_params):\n",
    "                return self\n",
    "\n",
    "        # The preprocessor set here is just a default and gets overwritten by the possible preprocessors in the parameter space\n",
    "        pipeline = Pipeline([(\"debug1\", Debug()), ('preprocessor', CountVectorizer()), (\"debug2\", Debug()), ('oversampler', SMOTE()), ('estimator', model)])\n",
    "\n",
    "        # Setting up the Cross validation\n",
    "        inner_cv = RepeatedStratifiedKFold(n_splits = cv_splits, n_repeats = cv_repeats, random_state = 33)\n",
    "        outer_cv = RepeatedStratifiedKFold(n_splits = cv_splits, n_repeats = cv_repeats, random_state = 33)\n",
    "\n",
    "        # Doing hyperparameter optimization\n",
    "        optimization = RandomizedSearchCV(\n",
    "            estimator = pipeline,\n",
    "            param_distributions = params,\n",
    "            scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', 'roc_auc_ovo_weighted'],\n",
    "            cv = inner_cv,\n",
    "            refit = 'roc_auc_ovo_weighted',\n",
    "            n_iter = iterations,\n",
    "            n_jobs = os.cpu_count() -1,\n",
    "            verbose = 1,\n",
    "            random_state = 33)\n",
    "\n",
    "        optimization.fit(np.array(range(len(self.data))), self.data[self.target])\n",
    "\n",
    "        # Evaluating the best model on the outer cross validation\n",
    "        performance_estimation = cross_validate(\n",
    "            estimator = optimization,\n",
    "            X = np.array(range(len(self.data))),\n",
    "            y = self.data[self.target],\n",
    "            scoring = ['accuracy', 'balanced_accuracy', 'f1_weighted', 'roc_auc_ovo_weighted'],\n",
    "            cv = outer_cv,\n",
    "            n_jobs = os.cpu_count() -1)\n",
    "\n",
    "        return(\n",
    "        {\n",
    "            'name': name,\n",
    "            'optimization_cv_results': pd.DataFrame(optimization.cv_results_),\n",
    "            'best_params': optimization.best_params_,\n",
    "            'best_model': optimization.best_estimator_,\n",
    "            'acc': performance_estimation['test_accuracy'],\n",
    "            'balanced_acc': performance_estimation['test_balanced_accuracy'],\n",
    "            'f1': performance_estimation['test_f1_weighted'],\n",
    "            'roc_auc': performance_estimation['test_roc_auc_ovo_weighted']\n",
    "        }\n",
    "        )\n",
    "\n",
    "    def run_experiments(self, iterations, cv_splits, cv_repeats, models = None):\n",
    "\n",
    "        self.experiment_results[f\"run_{self.__run}\"] = {}\n",
    "\n",
    "        # Determine which models to test\n",
    "        if models:\n",
    "            experiments = [experiment for experiment in self.experiments if experiment[\"name\"] in models]\n",
    "        else:\n",
    "            experiments = self.experiments\n",
    "\n",
    "        # Run experiment per model type\n",
    "        for experiment in experiments:\n",
    "\n",
    "            # Skip SVM\n",
    "            if experiment['name'] == 'SVM':\n",
    "                continue\n",
    "\n",
    "            start_time= time.time()\n",
    "\n",
    "            print()\n",
    "            print()\n",
    "            print(experiment['name'])\n",
    "            print(\"-----------------\")\n",
    "\n",
    "            self.experiment_results[f\"run_{self.__run}\"][experiment['name']] = self.evaluate_classifier(\n",
    "                    name = experiment['name'],\n",
    "                    model = experiment['model'],\n",
    "                    params = experiment['params'],\n",
    "                    iterations = iterations,\n",
    "                    cv_splits = cv_splits,\n",
    "                    cv_repeats = cv_repeats\n",
    "                )\n",
    "\n",
    "            end_time = time.time() - start_time\n",
    "            print(f'Time: {int(round(end_time, 1))} seconds ({int(round(end_time/60, 1))} minutes)')\n",
    "\n",
    "        self.__run += 1\n",
    "\n",
    "    # Function to aggregate hyperparameter optimization trials\n",
    "    def aggregate_parameter_search(self):\n",
    "\n",
    "        param_df = pd.DataFrame()\n",
    "\n",
    "        # Loop over experiment results\n",
    "        for run in self.experiment_results.keys():\n",
    "            for model_name in self.experiment_results[run]:\n",
    "\n",
    "                corresponding_experiment = next((item for item in self.experiments if item[\"name\"] == model_name), None)\n",
    "\n",
    "                # Convert to string\n",
    "                intermediate_df = self.experiment_results[run][model_name]['optimization_cv_results']\n",
    "                intermediate_df[[\"param_\" + s for s in list(corresponding_experiment['params'].keys())]] = intermediate_df[\n",
    "                    [\"param_\" + s for s in list(corresponding_experiment['params'].keys())]].astype(str)\n",
    "\n",
    "                # Loop over tested parameters\n",
    "                for param in list(corresponding_experiment['params'].keys()):\n",
    "\n",
    "                    param_agg = intermediate_df.groupby(\"param_\" + param).agg(\n",
    "                        times_tested = (\"param_\" + param, \"count\"),\n",
    "                        mean_auc = (\"mean_test_roc_auc_ovo_weighted\", np.mean)\n",
    "                    ).reset_index()\n",
    "                    param_agg.columns = [\"param_value\", \"times_tested\", \"mean_auc\"]\n",
    "                    param_agg[\"param\"] = param\n",
    "                    param_agg[\"model\"] = f'{run}-{model_name}'\n",
    "\n",
    "                    param_df = pd.concat([param_df, param_agg])\n",
    "\n",
    "        param_df[[\"model\", \"param\", \"param_value\", \"times_tested\", \"mean_auc\"]].sort_values(\n",
    "                [\"model\", \"param\", \"mean_auc\"], ascending = [True, True, False]).reset_index(drop = True)\n",
    "\n",
    "        self.param_search = param_df\n",
    "\n",
    "    def build_result_table(self):\n",
    "\n",
    "        # Looking at the results and building a result table\n",
    "        result_table = pd.DataFrame()\n",
    "        for run in self.experiment_results.keys():\n",
    "            for model_name in self.experiment_results[run]:\n",
    "                result = self.experiment_results[run][model_name]\n",
    "\n",
    "                print(result['name'])\n",
    "                print(result['best_params'])\n",
    "                print(np.mean(result['acc']))\n",
    "                print(np.mean(result['balanced_acc']))\n",
    "                print(np.mean(result['f1']))\n",
    "                print(np.mean(result['roc_auc']))\n",
    "                print()\n",
    "                result_table = pd.concat(\n",
    "                    [result_table, \n",
    "                    pd.DataFrame({\n",
    "                        'acc': np.mean(result['acc']),\n",
    "                        'balanced_acc': np.mean(result['balanced_acc']),\n",
    "                        'f1': np.mean(result['f1']),\n",
    "                        'roc_auc': np.mean(result['roc_auc'])\n",
    "                        },\n",
    "                        index = [model_name])\n",
    "                    ])\n",
    "\n",
    "        self.result_table = result_table\n",
    "\n",
    "    # Funtion for producing ROC curve and confusion matrix on single test split\n",
    "    def visualize_classifiers(self, test_share = 0.3):\n",
    "\n",
    "        # Refitting the best models on a single train test split to look at confusion matrix and ROC curve\n",
    "        X_train, X_test, y_train, y_test = train_test_split(np.array(range(len(self.data))), self.data[self.target], test_size=test_share, shuffle=True, random_state=33)\n",
    "        #X_train = pd.DataFrame(X_train, columns = features.columns)\n",
    "\n",
    "        # Plot object for ROC curve\n",
    "        plt.figure(figsize=[10,7.5])\n",
    "        roc_ax = plt.axes()\n",
    "        roc_ax.set_title(\"ROC Curves\")\n",
    "\n",
    "        # Adding naive prediction\n",
    "        naive_prediction_proba = self.data.naive_baseline_prediction\n",
    "        RocCurveDisplay.from_predictions(np.random.permutation(self.data[self.target]), naive_prediction_proba, name = \"Naive\", ax = roc_ax)\n",
    "\n",
    "        # Subplots for Confusion Matrix\n",
    "        fig, axs = plt.subplots(2, 2, figsize=[10,7.5])\n",
    "        positions = [(0,0),(0,1),(1,0),(1,1)]\n",
    "        position_index = 0\n",
    "\n",
    "        # Container for cutoff values\n",
    "        optimal_cutoffs = {}\n",
    "\n",
    "        # Looping over experiment results\n",
    "        for run in self.experiment_results.keys():\n",
    "            for result in self.experiment_results[run]:\n",
    "\n",
    "                # Refitting the model with the best parameter configuation (includes possible scaling and oversampling)\n",
    "                model = result['best_model']\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Prediction on the splitted test data\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "                # Visualizing\n",
    "                RocCurveDisplay.from_predictions(y_test, y_pred_prob, name = result['name'], ax = roc_ax)\n",
    "\n",
    "                ConfusionMatrixDisplay.from_predictions(\n",
    "                    y_test, y_pred, \n",
    "                    labels = [0,1], display_labels = [\"A\",\"F\"], \n",
    "                    ax = axs[positions[position_index]], colorbar = False, cmap = plt.cm.YlGnBu)\n",
    "                axs[positions[position_index]].set_title(result['name'])\n",
    "                position_index += 1\n",
    "\n",
    "                optimal_cutoffs[result['name']] = thresholds[np.argmax(tpr - fpr)]\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.suptitle(\"Confusion Matrices\")\n",
    "\n",
    "        print(optimal_cutoffs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing needs to be part of pipeline to prevent data leakage or cheating the out of vocabulary problem - additional computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of pipeline\n",
    "\n",
    "Convenience and encapsulation\n",
    "You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "\n",
    "Joint parameter selection\n",
    "You can grid search over parameters of all estimators in the pipeline at once.\n",
    "\n",
    "Safety\n",
    "Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produce word embeddings for - wv_glove_wiki\n",
      "Produce word embeddings for - wv_glove_twitter\n",
      "Produce word embeddings for - wv_word2vec\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Sentiment Analyser\n",
    "sentiment = SentimentAnalyser(yelp, \"stars\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.naive_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.vader_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.textblob_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Logistic Regression\n",
      "-----------------\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ValentinStudium\\Envs\\sma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "c:\\Users\\ValentinStudium\\Envs\\sma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\ValentinStudium\\Envs\\sma\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 52 seconds (0 minutes)\n"
     ]
    }
   ],
   "source": [
    "sentiment.run_experiments(5, 2, 1, [\"Logistic Regression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.aggregate_parameter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_value</th>\n",
       "      <th>times_tested</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>param</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.736009</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__WordEmbeddingHelper(data=array([[-0.0231393 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__WordEmbeddingHelper(data=array([[-0.07173365...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758720</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751976</td>\n",
       "      <td>oversampler</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>passthrough</td>\n",
       "      <td>2</td>\n",
       "      <td>0.759145</td>\n",
       "      <td>oversampler</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758720</td>\n",
       "      <td>estimator__penalty</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727901</td>\n",
       "      <td>estimator__penalty</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>0.762532</td>\n",
       "      <td>estimator__penalty</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>estimator__C</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743580</td>\n",
       "      <td>estimator__C</td>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         param_value  times_tested  mean_auc  \\\n",
       "0  __WordCountTransformerHelper(data=      stars ...             2  0.736009   \n",
       "1  __WordEmbeddingHelper(data=array([[-0.0231393 ...             2  0.771739   \n",
       "2  __WordEmbeddingHelper(data=array([[-0.07173365...             1  0.758720   \n",
       "0                             SMOTE(random_state=33)             3  0.751976   \n",
       "1                                        passthrough             2  0.759145   \n",
       "0                                         elasticnet             1  0.758720   \n",
       "1                                                 l1             1  0.727901   \n",
       "2                                               none             3  0.762532   \n",
       "0                                                0.5             2  0.771739   \n",
       "1                                                  2             3  0.743580   \n",
       "\n",
       "                param                      model  \n",
       "0        preprocessor  run_1-Logistic Regression  \n",
       "1        preprocessor  run_1-Logistic Regression  \n",
       "2        preprocessor  run_1-Logistic Regression  \n",
       "0         oversampler  run_1-Logistic Regression  \n",
       "1         oversampler  run_1-Logistic Regression  \n",
       "0  estimator__penalty  run_1-Logistic Regression  \n",
       "1  estimator__penalty  run_1-Logistic Regression  \n",
       "2  estimator__penalty  run_1-Logistic Regression  \n",
       "0        estimator__C  run_1-Logistic Regression  \n",
       "1        estimator__C  run_1-Logistic Regression  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.param_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "{'preprocessor': __WordEmbeddingHelper(data=array([[-0.0231393 ,  0.04741233,  0.01614293, ..., -0.02514256,\n",
      "         0.04803576,  0.00268555],\n",
      "       [-0.02278455,  0.04631694, -0.02104378, ..., -0.00500965,\n",
      "         0.05541738, -0.00547345],\n",
      "       [ 0.00243906,  0.02151313, -0.00636644, ..., -0.03804838,\n",
      "         0.00852438, -0.01802885],\n",
      "       ...,\n",
      "       [ 0.00030435,  0.04760577,  0.02483141, ..., -0.01444306,\n",
      "         0.03530873,  0.00304269],\n",
      "       [ 0.0184044 ,  0.04695504,  0.02700057, ..., -0.04469659,\n",
      "         0.01335864,  0.0114487 ],\n",
      "       [ 0.02122582,  0.03601752,  0.05741713, ..., -0.09107801,\n",
      "         0.01724688,  0.0259196 ]], dtype=float32)), 'oversampler': 'passthrough', 'estimator__penalty': 'none', 'estimator__C': 0.5}\n",
      "0.505123147885871\n",
      "0.44148800487378403\n",
      "0.5075594057615893\n",
      "0.7719379483124513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at the results and building a result table\n",
    "result_table = pd.DataFrame()\n",
    "for run in sentiment.experiment_results.keys():\n",
    "    for model_name in sentiment.experiment_results[run]:\n",
    "        result = sentiment.experiment_results[run][model_name]\n",
    "\n",
    "        print(result['name'])\n",
    "        print(result['best_params'])\n",
    "        print(np.mean(result['acc']))\n",
    "        print(np.mean(result['balanced_acc']))\n",
    "        print(np.mean(result['f1']))\n",
    "        print(np.mean(result['roc_auc']))\n",
    "        print()\n",
    "        result_table = pd.concat(\n",
    "            [result_table, \n",
    "            pd.DataFrame({\n",
    "                'acc': np.mean(result['acc']),\n",
    "                'balanced_acc': np.mean(result['balanced_acc']),\n",
    "                'f1': np.mean(result['f1']),\n",
    "                'roc_auc': np.mean(result['roc_auc'])\n",
    "                },\n",
    "                index = [model_name])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_preprocessor</th>\n",
       "      <th>param_oversampler</th>\n",
       "      <th>param_estimator__penalty</th>\n",
       "      <th>param_estimator__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_f1_weighted</th>\n",
       "      <th>split1_test_f1_weighted</th>\n",
       "      <th>mean_test_f1_weighted</th>\n",
       "      <th>std_test_f1_weighted</th>\n",
       "      <th>rank_test_f1_weighted</th>\n",
       "      <th>split0_test_roc_auc_ovo_weighted</th>\n",
       "      <th>split1_test_roc_auc_ovo_weighted</th>\n",
       "      <th>mean_test_roc_auc_ovo_weighted</th>\n",
       "      <th>std_test_roc_auc_ovo_weighted</th>\n",
       "      <th>rank_test_roc_auc_ovo_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.007997</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>{'preprocessor': __WordCountTransformerHelper(...</td>\n",
       "      <td>0.536021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.515851</td>\n",
       "      <td>0.517541</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741777</td>\n",
       "      <td>0.745971</td>\n",
       "      <td>0.743874</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.158192</td>\n",
       "      <td>0.265013</td>\n",
       "      <td>0.328636</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'preprocessor': __WordCountTransformerHelper(...</td>\n",
       "      <td>0.508262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509648</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>0.508201</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726744</td>\n",
       "      <td>0.729023</td>\n",
       "      <td>0.727883</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.778363</td>\n",
       "      <td>1.321301</td>\n",
       "      <td>0.113001</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>2</td>\n",
       "      <td>{'preprocessor': FunctionTransformer(func=&lt;bou...</td>\n",
       "      <td>0.461335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475451</td>\n",
       "      <td>0.484169</td>\n",
       "      <td>0.479810</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>5</td>\n",
       "      <td>0.754600</td>\n",
       "      <td>0.762831</td>\n",
       "      <td>0.758716</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.081300</td>\n",
       "      <td>0.884419</td>\n",
       "      <td>0.047293</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'preprocessor': FunctionTransformer(func=&lt;bou...</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473662</td>\n",
       "      <td>0.510212</td>\n",
       "      <td>0.491937</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>4</td>\n",
       "      <td>0.761744</td>\n",
       "      <td>0.776922</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.981482</td>\n",
       "      <td>0.299022</td>\n",
       "      <td>0.041763</td>\n",
       "      <td>0.010763</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'preprocessor': FunctionTransformer(func=&lt;bou...</td>\n",
       "      <td>0.504957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501441</td>\n",
       "      <td>0.516199</td>\n",
       "      <td>0.508820</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766819</td>\n",
       "      <td>0.781565</td>\n",
       "      <td>0.774192</td>\n",
       "      <td>0.007373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.007997      0.007998         0.342000        0.010999   \n",
       "1      21.158192      0.265013         0.328636        0.024636   \n",
       "2      26.778363      1.321301         0.113001        0.000997   \n",
       "3       8.081300      0.884419         0.047293        0.001290   \n",
       "4       2.981482      0.299022         0.041763        0.010763   \n",
       "\n",
       "                                  param_preprocessor       param_oversampler  \\\n",
       "0  __WordCountTransformerHelper(data=      stars ...             passthrough   \n",
       "1  __WordCountTransformerHelper(data=      stars ...  SMOTE(random_state=33)   \n",
       "2  FunctionTransformer(func=<bound method Sentime...  SMOTE(random_state=33)   \n",
       "3  FunctionTransformer(func=<bound method Sentime...  SMOTE(random_state=33)   \n",
       "4  FunctionTransformer(func=<bound method Sentime...             passthrough   \n",
       "\n",
       "  param_estimator__penalty param_estimator__C  \\\n",
       "0                     none                  2   \n",
       "1                       l1                  2   \n",
       "2               elasticnet                  2   \n",
       "3                     none                0.5   \n",
       "4                     none                0.5   \n",
       "\n",
       "                                              params  split0_test_accuracy  \\\n",
       "0  {'preprocessor': __WordCountTransformerHelper(...              0.536021   \n",
       "1  {'preprocessor': __WordCountTransformerHelper(...              0.508262   \n",
       "2  {'preprocessor': FunctionTransformer(func=<bou...              0.461335   \n",
       "3  {'preprocessor': FunctionTransformer(func=<bou...              0.461996   \n",
       "4  {'preprocessor': FunctionTransformer(func=<bou...              0.504957   \n",
       "\n",
       "   ...  split0_test_f1_weighted  split1_test_f1_weighted  \\\n",
       "0  ...                 0.519231                 0.515851   \n",
       "1  ...                 0.509648                 0.506755   \n",
       "2  ...                 0.475451                 0.484169   \n",
       "3  ...                 0.473662                 0.510212   \n",
       "4  ...                 0.501441                 0.516199   \n",
       "\n",
       "   mean_test_f1_weighted  std_test_f1_weighted  rank_test_f1_weighted  \\\n",
       "0               0.517541              0.001690                      1   \n",
       "1               0.508201              0.001446                      3   \n",
       "2               0.479810              0.004359                      5   \n",
       "3               0.491937              0.018275                      4   \n",
       "4               0.508820              0.007379                      2   \n",
       "\n",
       "   split0_test_roc_auc_ovo_weighted  split1_test_roc_auc_ovo_weighted  \\\n",
       "0                          0.741777                          0.745971   \n",
       "1                          0.726744                          0.729023   \n",
       "2                          0.754600                          0.762831   \n",
       "3                          0.761744                          0.776922   \n",
       "4                          0.766819                          0.781565   \n",
       "\n",
       "   mean_test_roc_auc_ovo_weighted  std_test_roc_auc_ovo_weighted  \\\n",
       "0                        0.743874                       0.002097   \n",
       "1                        0.727883                       0.001139   \n",
       "2                        0.758716                       0.004115   \n",
       "3                        0.769333                       0.007589   \n",
       "4                        0.774192                       0.007373   \n",
       "\n",
       "   rank_test_roc_auc_ovo_weighted  \n",
       "0                               4  \n",
       "1                               5  \n",
       "2                               3  \n",
       "3                               2  \n",
       "4                               1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.experiment_results[\"run_1\"][\"Logistic Regression\"]['optimization_cv_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param</th>\n",
       "      <th>param_value</th>\n",
       "      <th>times_tested</th>\n",
       "      <th>mean_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>estimator__C</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>estimator__C</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>estimator__penalty</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>0.762466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>estimator__penalty</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>estimator__penalty</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>oversampler</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>2</td>\n",
       "      <td>0.759033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>oversampler</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.771763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run_1-Logistic Regression</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.735878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model               param  \\\n",
       "0  run_1-Logistic Regression        estimator__C   \n",
       "1  run_1-Logistic Regression        estimator__C   \n",
       "2  run_1-Logistic Regression  estimator__penalty   \n",
       "3  run_1-Logistic Regression  estimator__penalty   \n",
       "4  run_1-Logistic Regression  estimator__penalty   \n",
       "5  run_1-Logistic Regression         oversampler   \n",
       "6  run_1-Logistic Regression         oversampler   \n",
       "7  run_1-Logistic Regression        preprocessor   \n",
       "8  run_1-Logistic Regression        preprocessor   \n",
       "9  run_1-Logistic Regression        preprocessor   \n",
       "\n",
       "                                         param_value  times_tested  mean_auc  \n",
       "0                                                0.5             2  0.771763  \n",
       "1                                                  2             3  0.743491  \n",
       "2                                               none             3  0.762466  \n",
       "3                                         elasticnet             1  0.758716  \n",
       "4                                                 l1             1  0.727883  \n",
       "5                                        passthrough             2  0.759033  \n",
       "6                             SMOTE(random_state=33)             3  0.751977  \n",
       "7  FunctionTransformer(func=<bound method Sentime...             2  0.771763  \n",
       "8  FunctionTransformer(func=<bound method Sentime...             1  0.758716  \n",
       "9  __WordCountTransformerHelper(data=      stars ...             2  0.735878  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_df = pd.DataFrame()\n",
    "\n",
    "# Loop over experiment results\n",
    "for run in sentiment.experiment_results.keys():\n",
    "    for model_name in sentiment.experiment_results[run]:\n",
    "\n",
    "        corresponding_experiment = next((item for item in sentiment.experiments if item[\"name\"] == model_name), None)\n",
    "\n",
    "        # Convert to string\n",
    "        intermediate_df = sentiment.experiment_results[run][model_name]['optimization_cv_results']\n",
    "        intermediate_df[[\"param_\" + s for s in list(corresponding_experiment['params'].keys())]] = intermediate_df[\n",
    "            [\"param_\" + s for s in list(corresponding_experiment['params'].keys())]].astype(str)\n",
    "\n",
    "        # Loop over tested parameters\n",
    "        for param in list(corresponding_experiment['params'].keys()):\n",
    "\n",
    "            param_agg = intermediate_df.groupby(\"param_\" + param).agg(\n",
    "                times_tested = (\"param_\" + param, \"count\"),\n",
    "                mean_auc = (\"mean_test_roc_auc_ovo_weighted\", np.mean)\n",
    "            ).reset_index()\n",
    "            param_agg.columns = [\"param_value\", \"times_tested\", \"mean_auc\"]\n",
    "            param_agg[\"param\"] = param\n",
    "            param_agg[\"model\"] = f'{run}-{model_name}'\n",
    "\n",
    "            param_df = pd.concat([param_df, param_agg])\n",
    "\n",
    "param_df[[\"model\", \"param\", \"param_value\", \"times_tested\", \"mean_auc\"]].sort_values(\n",
    "        [\"model\", \"param\", \"mean_auc\"], ascending = [True, True, False]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;debug1&#x27;, Debug()),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 __TfidfTransformerHelper(data=      stars                                               text       date  \\\n",
       "0       5.0  fantastic little restaurantgreat staff food go... 2017-08-12   \n",
       "1       4.0  went grab breakfast cafe also lunch small snac... 2015-09-29   \n",
       "2       4.0  good coffee sandwiches yogurts close marriott ... 2016-01-13   \n",
       "3       3.0  xing handed coupons free coffee drinks new cam... 2008-04-24   \n",
       "4       4.0  love campus suite franchise...\n",
       "3024  {&#x27;neg&#x27;: 0.174, &#x27;neu&#x27;: 0.436, &#x27;pos&#x27;: 0.389, &#x27;co...          0.7506   \n",
       "\n",
       "      vader_prediction  textblob_score  textblob_prediction  \n",
       "0                    1        0.151389                    1  \n",
       "1                    1        0.247917                    1  \n",
       "2                    1        0.525000                    1  \n",
       "3                    1        0.214388                    1  \n",
       "4                    1        0.440000                    1  \n",
       "...                ...             ...                  ...  \n",
       "3020                 1        0.237500                    1  \n",
       "3021                 0        0.127857                    1  \n",
       "3022                 1        0.236111                    1  \n",
       "3023                 0        0.156410                    1  \n",
       "3024                 1        0.042424                    1  \n",
       "\n",
       "[3025 rows x 10 columns])),\n",
       "                (&#x27;debug2&#x27;, Debug()), (&#x27;oversampler&#x27;, SMOTE(random_state=33)),\n",
       "                (&#x27;estimator&#x27;,\n",
       "                 LogisticRegression(C=2, l1_ratio=0.5, n_jobs=7,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;debug1&#x27;, Debug()),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 __TfidfTransformerHelper(data=      stars                                               text       date  \\\n",
       "0       5.0  fantastic little restaurantgreat staff food go... 2017-08-12   \n",
       "1       4.0  went grab breakfast cafe also lunch small snac... 2015-09-29   \n",
       "2       4.0  good coffee sandwiches yogurts close marriott ... 2016-01-13   \n",
       "3       3.0  xing handed coupons free coffee drinks new cam... 2008-04-24   \n",
       "4       4.0  love campus suite franchise...\n",
       "3024  {&#x27;neg&#x27;: 0.174, &#x27;neu&#x27;: 0.436, &#x27;pos&#x27;: 0.389, &#x27;co...          0.7506   \n",
       "\n",
       "      vader_prediction  textblob_score  textblob_prediction  \n",
       "0                    1        0.151389                    1  \n",
       "1                    1        0.247917                    1  \n",
       "2                    1        0.525000                    1  \n",
       "3                    1        0.214388                    1  \n",
       "4                    1        0.440000                    1  \n",
       "...                ...             ...                  ...  \n",
       "3020                 1        0.237500                    1  \n",
       "3021                 0        0.127857                    1  \n",
       "3022                 1        0.236111                    1  \n",
       "3023                 0        0.156410                    1  \n",
       "3024                 1        0.042424                    1  \n",
       "\n",
       "[3025 rows x 10 columns])),\n",
       "                (&#x27;debug2&#x27;, Debug()), (&#x27;oversampler&#x27;, SMOTE(random_state=33)),\n",
       "                (&#x27;estimator&#x27;,\n",
       "                 LogisticRegression(C=2, l1_ratio=0.5, n_jobs=7,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Debug</label><div class=\"sk-toggleable__content\"><pre>Debug()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">__TfidfTransformerHelper</label><div class=\"sk-toggleable__content\"><pre>__TfidfTransformerHelper(data=      stars                                               text       date  \\\n",
       "0       5.0  fantastic little restaurantgreat staff food go... 2017-08-12   \n",
       "1       4.0  went grab breakfast cafe also lunch small snac... 2015-09-29   \n",
       "2       4.0  good coffee sandwiches yogurts close marriott ... 2016-01-13   \n",
       "3       3.0  xing handed coupons free coffee drinks new cam... 2008-04-24   \n",
       "4       4.0  love campus suite franchise balzac favorite pl... 2010-01-15   \n",
       "...     ...                                                ...        ...   \n",
       "3020    3.0  sur...\n",
       "3022  {&#x27;neg&#x27;: 0.0, &#x27;neu&#x27;: 0.777, &#x27;pos&#x27;: 0.223, &#x27;comp...          0.8628   \n",
       "3023  {&#x27;neg&#x27;: 0.134, &#x27;neu&#x27;: 0.768, &#x27;pos&#x27;: 0.098, &#x27;co...         -0.0806   \n",
       "3024  {&#x27;neg&#x27;: 0.174, &#x27;neu&#x27;: 0.436, &#x27;pos&#x27;: 0.389, &#x27;co...          0.7506   \n",
       "\n",
       "      vader_prediction  textblob_score  textblob_prediction  \n",
       "0                    1        0.151389                    1  \n",
       "1                    1        0.247917                    1  \n",
       "2                    1        0.525000                    1  \n",
       "3                    1        0.214388                    1  \n",
       "4                    1        0.440000                    1  \n",
       "...                ...             ...                  ...  \n",
       "3020                 1        0.237500                    1  \n",
       "3021                 0        0.127857                    1  \n",
       "3022                 1        0.236111                    1  \n",
       "3023                 0        0.156410                    1  \n",
       "3024                 1        0.042424                    1  \n",
       "\n",
       "[3025 rows x 10 columns])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Debug</label><div class=\"sk-toggleable__content\"><pre>Debug()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(random_state=33)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=2, l1_ratio=0.5, n_jobs=7, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('debug1', Debug()),\n",
       "                ('preprocessor',\n",
       "                 __TfidfTransformerHelper(data=      stars                                               text       date  \\\n",
       "0       5.0  fantastic little restaurantgreat staff food go... 2017-08-12   \n",
       "1       4.0  went grab breakfast cafe also lunch small snac... 2015-09-29   \n",
       "2       4.0  good coffee sandwiches yogurts close marriott ... 2016-01-13   \n",
       "3       3.0  xing handed coupons free coffee drinks new cam... 2008-04-24   \n",
       "4       4.0  love campus suite franchise...\n",
       "3024  {'neg': 0.174, 'neu': 0.436, 'pos': 0.389, 'co...          0.7506   \n",
       "\n",
       "      vader_prediction  textblob_score  textblob_prediction  \n",
       "0                    1        0.151389                    1  \n",
       "1                    1        0.247917                    1  \n",
       "2                    1        0.525000                    1  \n",
       "3                    1        0.214388                    1  \n",
       "4                    1        0.440000                    1  \n",
       "...                ...             ...                  ...  \n",
       "3020                 1        0.237500                    1  \n",
       "3021                 0        0.127857                    1  \n",
       "3022                 1        0.236111                    1  \n",
       "3023                 0        0.156410                    1  \n",
       "3024                 1        0.042424                    1  \n",
       "\n",
       "[3025 rows x 10 columns])),\n",
       "                ('debug2', Debug()), ('oversampler', SMOTE(random_state=33)),\n",
       "                ('estimator',\n",
       "                 LogisticRegression(C=2, l1_ratio=0.5, n_jobs=7,\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.experiment_results[\"run_1\"][\"Logistic Regression\"][\"best_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_preprocessor</th>\n",
       "      <th>param_oversampler</th>\n",
       "      <th>param_estimator__penalty</th>\n",
       "      <th>param_estimator__C</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_balanced_accuracy</th>\n",
       "      <th>mean_test_f1_weighted</th>\n",
       "      <th>mean_test_roc_auc_ovo_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.318205</td>\n",
       "      <td>__TfidfTransformerHelper(data=      stars     ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>2</td>\n",
       "      <td>0.461818</td>\n",
       "      <td>0.208965</td>\n",
       "      <td>0.315941</td>\n",
       "      <td>0.733758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.040036</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.403120</td>\n",
       "      <td>0.512948</td>\n",
       "      <td>0.735530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.528947</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>0.514380</td>\n",
       "      <td>0.403064</td>\n",
       "      <td>0.514678</td>\n",
       "      <td>0.735762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.818651</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.510083</td>\n",
       "      <td>0.402620</td>\n",
       "      <td>0.510977</td>\n",
       "      <td>0.736365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97.271674</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>2</td>\n",
       "      <td>0.514711</td>\n",
       "      <td>0.409362</td>\n",
       "      <td>0.516056</td>\n",
       "      <td>0.737924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38.189593</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510413</td>\n",
       "      <td>0.409068</td>\n",
       "      <td>0.512785</td>\n",
       "      <td>0.738820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.469869</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.418579</td>\n",
       "      <td>0.517431</td>\n",
       "      <td>0.738845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24.242758</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513388</td>\n",
       "      <td>0.413321</td>\n",
       "      <td>0.515778</td>\n",
       "      <td>0.740278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.842883</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.475041</td>\n",
       "      <td>0.429271</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.756273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.522225</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540826</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>0.526874</td>\n",
       "      <td>0.760396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.877260</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545124</td>\n",
       "      <td>0.384997</td>\n",
       "      <td>0.530748</td>\n",
       "      <td>0.760891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.778891</td>\n",
       "      <td>__WordCountTransformerHelper(data=      stars ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>l1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541488</td>\n",
       "      <td>0.388149</td>\n",
       "      <td>0.528316</td>\n",
       "      <td>0.762311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.904667</td>\n",
       "      <td>__TfidfTransformerHelper(data=      stars     ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528264</td>\n",
       "      <td>0.302198</td>\n",
       "      <td>0.483326</td>\n",
       "      <td>0.763223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.029668</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475372</td>\n",
       "      <td>0.434522</td>\n",
       "      <td>0.490146</td>\n",
       "      <td>0.767193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.899711</td>\n",
       "      <td>__TfidfTransformerHelper(data=      stars     ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>0.540165</td>\n",
       "      <td>0.381567</td>\n",
       "      <td>0.525939</td>\n",
       "      <td>0.769666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.788732</td>\n",
       "      <td>__TfidfTransformerHelper(data=      stars     ...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>l1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.551074</td>\n",
       "      <td>0.373528</td>\n",
       "      <td>0.528241</td>\n",
       "      <td>0.780408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.281045</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.498512</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>0.508798</td>\n",
       "      <td>0.785598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.073935</td>\n",
       "      <td>__TfidfTransformerHelper(data=      stars     ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532231</td>\n",
       "      <td>0.451068</td>\n",
       "      <td>0.535416</td>\n",
       "      <td>0.788044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.208996</td>\n",
       "      <td>FunctionTransformer(func=&lt;bound method Sentime...</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>none</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.537190</td>\n",
       "      <td>0.437230</td>\n",
       "      <td>0.526933</td>\n",
       "      <td>0.790929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.641574</td>\n",
       "      <td>__TfidfTransformerHelper(data=      stars     ...</td>\n",
       "      <td>SMOTE(random_state=33)</td>\n",
       "      <td>l2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.548430</td>\n",
       "      <td>0.415839</td>\n",
       "      <td>0.542086</td>\n",
       "      <td>0.796748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                 param_preprocessor  \\\n",
       "9        1.318205  __TfidfTransformerHelper(data=      stars     ...   \n",
       "16       3.040036  __WordCountTransformerHelper(data=      stars ...   \n",
       "13       3.528947  __WordCountTransformerHelper(data=      stars ...   \n",
       "12       2.818651  __WordCountTransformerHelper(data=      stars ...   \n",
       "8       97.271674  __WordCountTransformerHelper(data=      stars ...   \n",
       "6       38.189593  __WordCountTransformerHelper(data=      stars ...   \n",
       "1       59.469869  __WordCountTransformerHelper(data=      stars ...   \n",
       "18      24.242758  __WordCountTransformerHelper(data=      stars ...   \n",
       "14      17.842883  FunctionTransformer(func=<bound method Sentime...   \n",
       "11       1.522225  __WordCountTransformerHelper(data=      stars ...   \n",
       "0        2.877260  __WordCountTransformerHelper(data=      stars ...   \n",
       "15      21.778891  __WordCountTransformerHelper(data=      stars ...   \n",
       "19       2.904667  __TfidfTransformerHelper(data=      stars     ...   \n",
       "2       41.029668  FunctionTransformer(func=<bound method Sentime...   \n",
       "17       1.899711  __TfidfTransformerHelper(data=      stars     ...   \n",
       "5        3.788732  __TfidfTransformerHelper(data=      stars     ...   \n",
       "3       16.281045  FunctionTransformer(func=<bound method Sentime...   \n",
       "10       2.073935  __TfidfTransformerHelper(data=      stars     ...   \n",
       "4        5.208996  FunctionTransformer(func=<bound method Sentime...   \n",
       "7        1.641574  __TfidfTransformerHelper(data=      stars     ...   \n",
       "\n",
       "         param_oversampler param_estimator__penalty param_estimator__C  \\\n",
       "9              passthrough               elasticnet                  2   \n",
       "16  SMOTE(random_state=33)                       l2                  1   \n",
       "13  SMOTE(random_state=33)                     none                  2   \n",
       "12  SMOTE(random_state=33)                       l2                0.5   \n",
       "8   SMOTE(random_state=33)               elasticnet                  2   \n",
       "6   SMOTE(random_state=33)               elasticnet                  1   \n",
       "1   SMOTE(random_state=33)                       l1                  2   \n",
       "18  SMOTE(random_state=33)                       l1                  1   \n",
       "14  SMOTE(random_state=33)                     none                0.5   \n",
       "11             passthrough                       l2                  1   \n",
       "0              passthrough                     none                  2   \n",
       "15             passthrough                       l1                  2   \n",
       "19             passthrough                       l1                  1   \n",
       "2   SMOTE(random_state=33)               elasticnet                  2   \n",
       "17             passthrough                     none                  2   \n",
       "5              passthrough                       l1                  2   \n",
       "3   SMOTE(random_state=33)                     none                0.5   \n",
       "10  SMOTE(random_state=33)                       l2                  2   \n",
       "4              passthrough                     none                0.5   \n",
       "7   SMOTE(random_state=33)                       l2                  2   \n",
       "\n",
       "    mean_test_accuracy  mean_test_balanced_accuracy  mean_test_f1_weighted  \\\n",
       "9             0.461818                     0.208965               0.315941   \n",
       "16            0.512397                     0.403120               0.512948   \n",
       "13            0.514380                     0.403064               0.514678   \n",
       "12            0.510083                     0.402620               0.510977   \n",
       "8             0.514711                     0.409362               0.516056   \n",
       "6             0.510413                     0.409068               0.512785   \n",
       "1             0.515702                     0.418579               0.517431   \n",
       "18            0.513388                     0.413321               0.515778   \n",
       "14            0.475041                     0.429271               0.489130   \n",
       "11            0.540826                     0.381336               0.526874   \n",
       "0             0.545124                     0.384997               0.530748   \n",
       "15            0.541488                     0.388149               0.528316   \n",
       "19            0.528264                     0.302198               0.483326   \n",
       "2             0.475372                     0.434522               0.490146   \n",
       "17            0.540165                     0.381567               0.525939   \n",
       "5             0.551074                     0.373528               0.528241   \n",
       "3             0.498512                     0.454008               0.508798   \n",
       "10            0.532231                     0.451068               0.535416   \n",
       "4             0.537190                     0.437230               0.526933   \n",
       "7             0.548430                     0.415839               0.542086   \n",
       "\n",
       "    mean_test_roc_auc_ovo_weighted  \n",
       "9                         0.733758  \n",
       "16                        0.735530  \n",
       "13                        0.735762  \n",
       "12                        0.736365  \n",
       "8                         0.737924  \n",
       "6                         0.738820  \n",
       "1                         0.738845  \n",
       "18                        0.740278  \n",
       "14                        0.756273  \n",
       "11                        0.760396  \n",
       "0                         0.760891  \n",
       "15                        0.762311  \n",
       "19                        0.763223  \n",
       "2                         0.767193  \n",
       "17                        0.769666  \n",
       "5                         0.780408  \n",
       "3                         0.785598  \n",
       "10                        0.788044  \n",
       "4                         0.790929  \n",
       "7                         0.796748  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.experiment_results[\"run_1\"][\"Logistic Regression\"][\"optimization_cv_results\"][[\"mean_fit_time\", \"param_preprocessor\", \"param_oversampler\", \"param_estimator__penalty\", \"param_estimator__C\", \"mean_test_accuracy\", \"mean_test_balanced_accuracy\", \"mean_test_f1_weighted\", \"mean_test_roc_auc_ovo_weighted\"]].sort_values(\"mean_test_roc_auc_ovo_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_min_results = sentiment.experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis on the document level\n",
    "\n",
    "# 1. Rule based\n",
    "    # Vader\n",
    "    # Text Blob\n",
    "# 2. ML based - Classification or Regression?\n",
    "    # own feature engineering plus defined models\n",
    "        # bag of words\n",
    "        # TD-IF\n",
    "        # word vectors\n",
    "    # Transformers"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2822d77ee51dbb640527abe329425380abdeab763840ac762f0d0bc769537fcd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
